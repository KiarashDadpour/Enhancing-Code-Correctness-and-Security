# Enhancing Code Correctness and Security with Large Language Models: A Hands-on Workshop
## Abstract 
With the rapid and growing use of software in security-critical and life-critical systems, code correctness and software security have become core challenges in software engineering and cryptography. Traditional security analysis and testing techniques remain widely used, but in many cases they are time-consuming and provide limited coverage of vulnerabilities.

In recent years, large language models (LLMs) have emerged as novel tools that can assist in generating, analyzing, and improving code. Thanks to their ability to understand text and code, these models can play an effective role in identifying logical errors, discovering security vulnerabilities, and proposing corrective patches.

In this hands-on workshop, participants will first learn the theoretical foundations of software security and static code analysis as well as basic concepts for applying large language models to code correctness and security. Using practical, real-world examples, attendees will practice how to apply these models to analyze and remediate vulnerable code across several programming languages (including C/C++, C#, PHP, Python, and Java). The workshop will also discuss limitations, threats, and security challenges arising from the use of large language models in development processesâ€”especially in life-critical systems.

By the end of the workshop, participants are expected to be able to apply AI-based tools to improve code correctness and security, and to gain a clearer understanding of the opportunities and risks of this technology in software security and cryptography.

## Lecturers
### [Dr. Reza Ebrahimi Atani](https://www.linkedin.com/in/rezaebrahimiatani/)
### Dr. Amir Tabatabaei
### [Asal MahmodiNezhad](https://www.linkedin.com/in/asal-mahmodi-26886235b/)
### [Kiarash Dadpour](https://www.linkedin.com/in/kiarash-dadpour/)
