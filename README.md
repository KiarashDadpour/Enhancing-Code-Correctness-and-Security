 # Enhancing Code Correctness and Security with Large Language Models
## Abstract 
With the rapid and growing use of software in security-critical and life-critical systems, code correctness and software security have become core challenges in software engineering and cryptography. Traditional security analysis and testing techniques remain widely used, but in many cases they are time-consuming and provide limited coverage of vulnerabilities.

In recent years, large language models (LLMs) have emerged as novel tools that can assist in generating, analyzing, and improving code. Thanks to their ability to understand text and code, these models can play an effective role in identifying logical errors, discovering security vulnerabilities, and proposing corrective patches.

In this hands-on workshop, participants will first learn the theoretical foundations of software security and static code analysis as well as basic concepts for applying large language models to code correctness and security. Using practical, real-world examples, attendees will practice how to apply these models to analyze and remediate vulnerable code across several programming languages (including C/C++, C#, PHP, Python, and Java). The workshop will also discuss limitations, threats, and security challenges arising from the use of large language models in development processesâ€”especially in life-critical systems.

By the end of the workshop, participants are expected to be able to apply AI-based tools to improve code correctness and security, and to gain a clearer understanding of the opportunities and risks of this technology in software security and cryptography.

## Workshop goals: 
- Overview of software security concepts and types of code analysis (static/dynamic).
- Introduction to common SAST frameworks and tools for various programming languages.
- Limitations and challenges of traditional static analysis tools.
- Brief introduction to large language models and approaches to adapting/tuning them for code analysis tasks.
- The role of large language models in complementing static analysis workflows.
- Core capabilities of LLMs for vulnerability identification and remediation.
- Prompt-engineering techniques for code review and analysis (including zero-shot and few-shot prompting).
- Practical vulnerability examples and detection: SQL Injection, XSS, Buffer Overflow.
- Comparison of approaches: Zero-shot/Few-shot prompting vs. Fine-tuning.
- Evaluation methods and metrics to compare LLMs with traditional SAST tools.
## Lecturers
### [Dr. Reza Ebrahimi Atani](https://www.linkedin.com/in/rezaebrahimiatani/)
### Dr. Amir Tabatabaei
### [Asal MahmodiNezhad](https://www.linkedin.com/in/asal-mahmodi-26886235b/)
### [Kiarash Dadpour](https://www.linkedin.com/in/kiarash-dadpour/)

###### October, 2025
